{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from random import random\n",
    "from csv import reader\n",
    "from math import exp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Python script for confusion matrix creation.\n",
    "\n",
    "def ANN():\n",
    "\n",
    "    def load_csv(filename):\n",
    "        with open(filename, 'r') as file:\n",
    "            lines = csv.reader(file)\n",
    "            dataset=list(lines)\n",
    "    #    print(dataset)\n",
    "        return dataset\n",
    "\n",
    "    # Convert string column to float\n",
    "    def str_column_to_float(dataset, column):\n",
    "        for row in dataset:\n",
    "            row[column] = float(row[column])\n",
    "\n",
    "    # Convert string column to integer\n",
    "    def str_column_to_int(dataset, column):\n",
    "        class_values = [row[column] for row in dataset]\n",
    "        unique = set(class_values)\n",
    "        lookup = dict()\n",
    "        for i, value in enumerate(unique):\n",
    "            lookup[value] = i\n",
    "        for row in dataset:\n",
    "            row[column] = lookup[row[column]]\n",
    "       # print(lookup)\n",
    "       #print(dataset)\n",
    "        return lookup\n",
    "\n",
    "    # Find the min and max values for each column\n",
    "    def dataset_minmax(dataset):\n",
    "        minmax = list()\n",
    "        stats = [[min(column), max(column)] for column in zip(*dataset)]\n",
    "        return stats\n",
    "\n",
    "    # Rescale dataset columns to the range 0-1\n",
    "    def normalize_dataset(dataset, minmax):\n",
    "        for row in dataset:\n",
    "            for i in range(len(row)-1):\n",
    "                row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "\n",
    "    # Split a dataset into k folds\n",
    "    def cross_validation_split(dataset, n_folds):\n",
    "        dataset_split = list()\n",
    "        dataset_copy = list(dataset)\n",
    "        fold_size = int(len(dataset) / n_folds)\n",
    "        for i in range(n_folds):\n",
    "            fold = list()\n",
    "            while len(fold) < fold_size:\n",
    "                index = randrange(len(dataset_copy))\n",
    "                fold.append(dataset_copy.pop(index))\n",
    "            dataset_split.append(fold)\n",
    "        return dataset_split\n",
    "\n",
    "    # Calculate accuracy percentage\n",
    "    def accuracy_metric(actual, predicted):\n",
    "        correct = 0\n",
    "        for i in range(len(actual)):\n",
    "            if actual[i] == predicted[i]:\n",
    "                correct += 1\n",
    "        return correct / float(len(actual)) * 100.0\n",
    "\n",
    "    # Initialize a network\n",
    "    def initialize_network(n_inputs, n_hidden1, n_hidden2, n_outputs):\n",
    "            #print(\"No. of  Nuerons in Input layer: \", n_inputs)\n",
    "            #print(\"No. of  Nuerons in Hidden Layer 1: \", n_hidden1)\n",
    "            #print(\"No. of  Nuerons in Hidden Layer 2: \", n_hidden2)\n",
    "            #print(\"No. of  Nuerons in Output layer: \", n_outputs)\n",
    "            network = list()\n",
    "            hidden_layer1 = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
    "            network.append(hidden_layer1)\n",
    "            hidden_layer2 = [{'weights':[random() for i in range(n_hidden1 + 1)]} for i in range(n_hidden2)]\n",
    "            network.append(hidden_layer2)\n",
    "            output_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
    "            network.append(output_layer)\n",
    "            #print(network)\n",
    "            return network\n",
    "\n",
    "    # Calculate neuron activation for an input\n",
    "    def activate(weights, inputs):\n",
    "        activation = weights[-1]\n",
    "        for i in range(len(weights)-1):\n",
    "            activation += weights[i] * inputs[i]       #Complete the missing statement\n",
    "        return activation\n",
    "\n",
    "\n",
    "    #Complete the missing function to Transfer neuron activation\n",
    "\n",
    "    def transfer(activation):\n",
    "        return 1.0 / (1.0 + exp(-activation))\n",
    "\n",
    "    # Forward propagate input to a network output\n",
    "    def forward_propagate(network, row):\n",
    "        inputs = row\n",
    "        for layer in network:\n",
    "            new_inputs = []\n",
    "            for neuron in layer:\n",
    "                activation = activate(neuron['weights'], inputs)\n",
    "                neuron['output'] = transfer(activation)\n",
    "                new_inputs.append(neuron['output'])\n",
    "            inputs = new_inputs\n",
    "        return inputs\n",
    "\n",
    "    # Calculate the derivative of an neuron output\n",
    "    def transfer_derivative(output):\n",
    "        return output * (1.0 - output)\n",
    "\n",
    "    # Backpropagate error and store in neurons\n",
    "    def backward_propagate_error(network, expected):\n",
    "        for i in reversed(range(len(network))):\n",
    "            layer = network[i]\n",
    "            errors = list()\n",
    "            #For Hidden layer\n",
    "            if i != len(network)-1:\n",
    "                for j in range(len(layer)):\n",
    "                    error = 0.0\n",
    "                    for neuron in network[i + 1]:\n",
    "                        error += (neuron['weights'][j] * neuron['delta'])\n",
    "                    errors.append(error)\n",
    "            #For Output layer\n",
    "            else:\n",
    "                for j in range(len(layer)):\n",
    "                    neuron = layer[j]\n",
    "                    errors.append(expected[j] - neuron['output'])\n",
    "            for j in range(len(layer)):\n",
    "                neuron = layer[j]\n",
    "                neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n",
    "\n",
    "    # Update network weights with error\n",
    "    def update_weights(network, row, l_rate): # introduced bug\n",
    "        for i in range(len(network)):\n",
    "            inputs = row[:-1]\n",
    "            if i != 0:\n",
    "                inputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "            for neuron in network[i]:\n",
    "                for j in range(len(inputs)):\n",
    "                    neuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
    "                neuron['weights'][-1] += l_rate * neuron['delta']\n",
    "\n",
    "    # Train a network for a fixed number of epochs\n",
    "    def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "        for epoch in range(n_epoch):\n",
    "            for row in train:\n",
    "                outputs = forward_propagate(network, row)\n",
    "                expected = [0 for i in range(n_outputs)]\n",
    "                expected[row[-1]] = 1\n",
    "                backward_propagate_error(network, expected)\n",
    "                update_weights(network, row, l_rate)\n",
    "\n",
    "     # Make a prediction with a network\n",
    "    def predict(network, row):\n",
    "        outputs = forward_propagate(network, row)\n",
    "        return outputs.index(max(outputs))\n",
    "\n",
    "    # Backpropagation Algorithm With Stochastic Gradient Descent\n",
    "    def applying(train, test, l_rate, n_epoch, n_hidden):\n",
    "        n_inputs = len(train[0]) - 1\n",
    "        n_outputs = len(set([row[-1] for row in train]))\n",
    "        network = initialize_network(n_inputs, n_hidden, n_hidden, n_outputs)\n",
    "        train_network(network, train, l_rate, n_epoch, n_outputs)\n",
    "        predictions = list()\n",
    "        for row in test:\n",
    "            prediction = predict(network, row)\n",
    "            predictions.append(prediction)\n",
    "        return(predictions)\n",
    "\n",
    "    #Using all the functions\n",
    "    seed(1)\n",
    "    #Loading and preprocessing data\n",
    "    filename = 'leaf.csv'\n",
    "    dataset = load_csv(filename)\n",
    "    for i in range(len(dataset[0])-1):\n",
    "        str_column_to_float(dataset, i)\n",
    "    #Converting class column to integers\n",
    "    look = str_column_to_int(dataset, len(dataset[0])-1)\n",
    "    #print(look)\n",
    "    #Normalize input variables\n",
    "    minmax = dataset_minmax(dataset)\n",
    "    normalize_dataset(dataset, minmax)\n",
    "    n_folds = 5\n",
    "    l_rate = 0.3\n",
    "    n_epoch = 100\n",
    "    n_hidden = 5\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "            actual = [row[-1] for row in fold]\n",
    "    #print(actual)\n",
    "    print()\n",
    "    #for i in [0, 10, 100, 500, 1000, 10000]:       # For Training Dataset\n",
    "    #for i in [0.01, 0.2, 0.0001, 0.5, 1]:\n",
    "    result=applying(train_set,test_set, l_rate , n_epoch ,n_hidden)\n",
    "    #print(result)\n",
    "    acc=accuracy_metric(actual,result)\n",
    "    check = ''\n",
    "    check = \"Accuracy : \" + str(\"{0:.2f}\".format(acc * 5)) + \"\\n\"\n",
    "    matrix = []\n",
    "    for i in range(40):\n",
    "        l = list()\n",
    "        for j in range(40):\n",
    "            l.append(0)\n",
    "        matrix.append(l)\n",
    "    for i in range(len(actual)):\n",
    "        matrix[int(actual[i] - 1)][int(result[i] - 1)] += 1\n",
    "    check2 = ''\n",
    "    for i in matrix:\n",
    "        check2 += str(i) + \"\\n\"\n",
    "    from tkinter import messagebox\n",
    " \n",
    "    messagebox.showinfo(\"Confusion Matrix\", check2)\n",
    "\n",
    "    ann = tk.Tk()\n",
    "    ann.geometry(\"300x400\")\n",
    "    ann.resizable(0,0)\n",
    "    v = tk.IntVar()\n",
    "\n",
    "    languages = [\n",
    "        (\"Test\",1),\n",
    "    ]\n",
    "\n",
    "    def ShowChoice():\n",
    "        if (v.get() == 0):\n",
    "            image_accept()\n",
    "         \n",
    "\n",
    "    tk.Label(ann, \n",
    "             text=check,\n",
    "             justify = tk.CENTER, fg=\"#383a39\", bg=\"#a1dbcd\", font=(\"Helvetica\", 16),\n",
    "             padx = 20).pack()\n",
    "\n",
    "    for val, language in enumerate(languages):\n",
    "        tk.Radiobutton(ann, \n",
    "                      text=language,\n",
    "                      indicatoron = 0,\n",
    "                      width = 100,\n",
    "                      padx = 20, \n",
    "                      variable=v, \n",
    "                      command=ShowChoice,\n",
    "                      value=val).pack(anchor=tk.W)\n",
    "    ann.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kNN():\n",
    "    import csv\n",
    "    import random\n",
    "    import math\n",
    "    import operator\n",
    "    from pprint import pprint\n",
    "\n",
    "    random.seed(5)\n",
    "    def dataload(file,split,train=[],test=[]):\n",
    "        with open(file,'r') as csvfile:\n",
    "            lines=csv.reader(csvfile)\n",
    "            data=list(lines)\n",
    "\n",
    "            for x in range(len(data)-1):\n",
    "                for y in range(38):\t\n",
    "                    data[x][y]=float(data[x][y])\n",
    "                if(random.random()<split):\n",
    "                    train.append(data[x])\n",
    "                else:\n",
    "                    test.append(data[x])\n",
    "\n",
    "    # DONE\n",
    "    def Edistance(x1,x2,length):\n",
    "        s = 0\n",
    "        #print(x1)\n",
    "        for i in range(length):\n",
    "            s = s + (x1[i]-x2[i] )**2\n",
    "        return s**0.5\n",
    "\n",
    "    def Mdistance(x1,x2,length):\n",
    "        s = 0\n",
    "        for i in range(length):\n",
    "            s = s + (abs(x1[i]-x2[i]))\n",
    "        return s\n",
    "\n",
    "    def Cdistance(x1,x2,length):\n",
    "        s = 0\n",
    "        x1Square = [_**2 for _ in x1[:-1]]\n",
    "        x2Square = [_**2 for _ in x2[:-1]]\n",
    "        x1Sum = sum(x1Square)\n",
    "        x2Sum = sum(x2Square)\n",
    "        prod = 0\n",
    "        for i in range(length):\n",
    "            prod = prod + (x1[i]*x2[i])\n",
    "        sim = prod/((x1Sum**0.5) * (x2Sum**0.5))\n",
    "        return math.acos(sim)/math.pi\n",
    "\n",
    "    def distance(x1,x2,length,dist):\n",
    "        if(dist is \"E\"):\n",
    "            return Edistance(x1,x2,length)\n",
    "        if(dist is \"M\"):\n",
    "            return Mdistance(x1,x2,length)\n",
    "        if(dist is \"C\"):\n",
    "            return Cdistance(x1,x2,length)\n",
    "\n",
    "    def Neighbors(train, test, k,distType):\n",
    "        distances = []\n",
    "        length = len(test)-1\n",
    "\n",
    "        for x in range(len(train)):\n",
    "            dist = distance(test, train[x], length,distType)\n",
    "            distances.append((train[x], dist))\n",
    "        distances.sort(key=operator.itemgetter(1))\n",
    "        neighbors = []\n",
    "        for x in range(k):\n",
    "            neighbors.append(distances[x][0])\n",
    "        return neighbors\n",
    "\n",
    "    def Response(neighbors):\n",
    "        Votes = {}\n",
    "        #pprint(neighbors)\n",
    "        for x in range(len(neighbors)):\n",
    "            response = neighbors[x][-1]\n",
    "            if response in Votes:\n",
    "                Votes[response] += 1\n",
    "            else:\n",
    "                Votes[response] = 1\n",
    "        sortedVotes = sorted(Votes.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        #print(sortedVotes)\n",
    "        return sortedVotes[0][0]\n",
    "\n",
    "    #Calculating Accuracy\n",
    "    def Accuracy(testSet, predictions):\n",
    "        correct = 0\n",
    "        for x in range(len(testSet)):\n",
    "            if testSet[x][-1] == predictions[x]:\n",
    "                correct += 1\n",
    "        return (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "    def calculation(test,trainingSet,k,distType):\n",
    "        predictions = list()\n",
    "        for x in range(len(test)):\n",
    "            neighbors = Neighbors(trainingSet, test[x], k,distType)\n",
    "            result = Response(neighbors)\n",
    "            predictions.append(result)\n",
    "            #print('Predicted=',result,', Actual=',test[x][-1])\n",
    "        accuracy =Accuracy(test, predictions)\n",
    "        return \" K = \" + str(k) + \" : \" + str(\"{0:.2f}\".format(accuracy * 3)) + \"\\n\"\n",
    "\n",
    "    def confusion(test,trainingSet,k,distType,matrix):\n",
    "        predictions = list()\n",
    "        for x in range(len(test)):\n",
    "            neighbors = Neighbors(trainingSet, test[x], k,distType)\n",
    "            result = Response(neighbors)\n",
    "            predictions.append(result)\n",
    "        for i in range(len(test)):\n",
    "            matrix[int(test[i][-1]-1)][int(predictions[i]-1)] += 1\n",
    "    \n",
    "    trainingSet=[]\n",
    "    test=[]\n",
    "    split = 0.7\n",
    "    dataload('leaf.csv', split, trainingSet, test)\n",
    "    predictions=[]\n",
    "    distType = \"M\"\n",
    "    check = \"Train set: \" + str(len(trainingSet)) + \"\\n\" + \"Test set: \" + str(len(test)) + \"\\n\"\n",
    "    for k in range(1,10):\n",
    "        check += calculation(test,trainingSet,k,distType)\n",
    "    matrix = []\n",
    "    for i in range(40):\n",
    "        l = list()\n",
    "        for j in range(40):\n",
    "            l.append(0)\n",
    "        matrix.append(l)\n",
    "    confusion(test,trainingSet,1,distType,matrix)\n",
    "    check2 = ''\n",
    "    for i in matrix:\n",
    "        check2 += str(i) + \"\\n\"\n",
    "        \n",
    "    \"\"\"master2 = tk.Tk()\n",
    "\n",
    "    w = tk.Message(master2, text=check2)\n",
    "    w.pack()\n",
    "\n",
    "    master2.mainloop()\"\"\"\n",
    "    \n",
    "    from tkinter import messagebox\n",
    " \n",
    "    messagebox.showinfo(\"Confusion Matrix\", check2)\n",
    "\n",
    "    knn = tk.Tk()\n",
    "    knn.geometry(\"300x400\")\n",
    "    knn.resizable(0,0)\n",
    "    v = tk.IntVar()\n",
    "\n",
    "    languages = [\n",
    "        (\"Test\",1),\n",
    "    ]\n",
    "\n",
    "    def ShowChoice():\n",
    "        if (v.get() == 0):\n",
    "            image_accept()\n",
    "         \n",
    "\n",
    "    tk.Label(knn, \n",
    "             text=check,\n",
    "             justify = tk.CENTER,fg=\"#383a39\", bg=\"#a1dbcd\", font=(\"Helvetica\", 16),\n",
    "             padx = 20).pack()\n",
    "\n",
    "    for val, language in enumerate(languages):\n",
    "        tk.Radiobutton(knn, \n",
    "                      text=language,\n",
    "                      indicatoron = 0,\n",
    "                      width = 100,\n",
    "                      padx = 20, \n",
    "                      variable=v, \n",
    "                      command=ShowChoice,\n",
    "                      value=val).pack(anchor=tk.W)\n",
    "    knn.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_accept():\n",
    "    import tkinter as tk\n",
    "    knn2 = tk.Tk()\n",
    "    #knn2.geometry(\"300x600\")\n",
    "    #knn2.resizable(0,0)\n",
    "    global var\n",
    "    var = tk.StringVar()\n",
    "\n",
    "    E1 = tk.Entry(knn2, textvariable = var, bd = 5, width = 100)\n",
    "    E1.pack(side = tk.LEFT)\n",
    "\n",
    "    def userinput():\n",
    "        global var\n",
    "        a = E1.get()\n",
    "        predict_final(a)\n",
    "\n",
    "    b = tk.Button(knn2, text = 'Submit', command = userinput, bg=\"#a1dbcd\")\n",
    "    b.pack(side = tk.BOTTOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statistics import median\n",
    "import matplotlib.image as mpimg      \n",
    "import matplotlib.pyplot as plt        \n",
    "import matplotlib.patches as mpatches  \n",
    "from skimage import measure            \n",
    "import scipy.ndimage as ndi            \n",
    "from pylab import rcParams\n",
    "from skimage.feature import corner_harris, corner_subpix, corner_peaks, CENSURE\n",
    "rcParams['figure.figsize'] = (6, 6)\n",
    "def predict_final(a):\n",
    "    \n",
    "    def convert_to_gray(path):\n",
    "        image = cv2.imread(path)\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        return gray_image\n",
    "\n",
    "    def convert_to_binary(path):\n",
    "        image = cv2.imread(path)\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        ret,thresh_img = cv2.threshold(gray_image,127,255,cv2.THRESH_BINARY)\n",
    "        bit_img = cv2.bitwise_not(thresh_img)\n",
    "        kernel = np.ones((5,5),np.uint8)\n",
    "        rem_noise = cv2.morphologyEx(bit_img, cv2.MORPH_OPEN, kernel)\n",
    "        smooth_img = cv2.medianBlur(rem_noise, 5)\n",
    "        return smooth_img\n",
    "\n",
    "    def get_centre(img):\n",
    "        cy, cx = ndi.center_of_mass(img)\n",
    "        return (cx, cy)\n",
    "\n",
    "    def get_margins(img):\n",
    "        detector = CENSURE()\n",
    "        detector.detect(img)\n",
    "        coords = corner_peaks(corner_harris(img), min_distance=5)\n",
    "        x = []\n",
    "        for i in coords:\n",
    "            for j in i:\n",
    "                x.append(j)\n",
    "        if len(x)<30:\n",
    "            for i in range(len(x)-1, 30):\n",
    "                x.append(0)\n",
    "        return(x[:30])\n",
    "\n",
    "    def get_texture_attr(img):\n",
    "        return(img.mean(), img.std(), median(img.flatten()))\n",
    "\n",
    "    def get_uniformity(img):\n",
    "        non = img.astype(np.float32)/255\n",
    "        uni = img.astype(np.float32)/255\n",
    "        blur_non = cv2.GaussianBlur(non, (11, 11), 2)\n",
    "        blur_uni = cv2.GaussianBlur(uni, (11, 11), 2)\n",
    "        for i in range(10):\n",
    "            blur_non = cv2.GaussianBlur(blur_non, (11, 11), 2)\n",
    "            blur_uni = cv2.GaussianBlur(blur_uni, (11, 11), 2)\n",
    "\n",
    "        last_blur_non = cv2.GaussianBlur(blur_non, (11, 11), 2)\n",
    "        last_blur_uni = cv2.GaussianBlur(blur_uni, (11, 11), 2)\n",
    "\n",
    "        ssd_blur_non = np.sum((last_blur_non - blur_non)**2)\n",
    "        ssd_blur_uni = np.sum((last_blur_uni - blur_uni)**2)\n",
    "\n",
    "        return(ssd_blur_non, ssd_blur_uni)\n",
    "\n",
    "    def randomForestClassifier(path):\n",
    "        feature_file = pd.read_csv('train_data.csv')\n",
    "        label_file = pd.read_csv('test_data.csv')\n",
    "        features = feature_file.values.tolist()\n",
    "        label = label_file\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        features_train, features_test, label_train, label_test = train_test_split(features, label, test_size=0.33)\n",
    "\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        clf = RandomForestClassifier(min_samples_split=5,n_estimators=100)\n",
    "        clf.fit(features_train, label_train)\n",
    "        img1 = convert_to_gray(path)\n",
    "        img2 = convert_to_binary(path)\n",
    "        cv2.imwrite('output_gray.jpg', img1)\n",
    "        cv2.imwrite('output_binary.jpg', img2)\n",
    "        a, c, b = get_texture_attr(img1)\n",
    "        d, e = get_uniformity(img1)\n",
    "        f, g = get_centre(img2)\n",
    "        h = get_margins(img2)\n",
    "        test = [a,b,c,d,e,f,g]\n",
    "        for i in range(30):\n",
    "            test.append(h[i])\n",
    "        output = clf.predict([test])\n",
    "\n",
    "        return(output)\n",
    "\n",
    "    species = ['Quercus suber', 'Salix atrocinerea', 'Populus nigra', 'Alnus sp', 'Quercus robur', 'Crataegus monogyna', 'Ilex aquifolium', 'Nerium oleander', 'Betula pubescens', 'Tilia tomentosa', 'Acer palmatum', 'Celtis sp.', 'Corylus avellana', 'Castanea sativa', 'Populus alba', 'Acer negundo', 'Taxus bacatta', 'Papaver sp.', 'Polypolium vulgare', 'Pinus sp.', 'Fraxinus sp.', 'Primula vulgaris', 'Erodium sp.', 'Bougainvillea sp.', 'Arisarum vulgare', 'Euonymus japonicus', 'Ilex perado ssp. azorica', 'Magnolia soulangeana', 'Buxus sempervirens', 'Urtica dioica', 'Podocarpus sp.', 'Acca sellowiana', 'Hydrangea sp.', 'Pseudosasa japonica', 'Magnolia grandiora','Geranium sp.','Aesculus californica','Chelidonium majus','Schinus terebinthifolius','Fragaria vesca']\n",
    "\n",
    "    path = a\n",
    "    [species_index] = randomForestClassifier(path)\n",
    "    print('The plant in the given image belongs to',species[species_index-1], 'species')\n",
    "    image_file = species[species_index-1] + \".jpg\"\n",
    "  \n",
    "    from PIL import Image,ImageTk  \n",
    "    rootimg = tk.Tk() \n",
    "    rootimg.geometry(\"100x100\")\n",
    "    rootimg.resizable(0,0)\n",
    "    rootimg.title(species[species_index-1])  \n",
    "    image=Image.open(image_file)  \n",
    "    im = image.resize((350, 300), Image.ANTIALIAS)\n",
    "    photo=ImageTk.PhotoImage(im)  \n",
    "    \n",
    "    cv = tk.Canvas(height=200, width=100)\n",
    "    cv.pack(side='top', fill='both', expand='yes')  \n",
    "    cv.create_image(150, 20, image=photo, anchor='nw')  \n",
    "    rootimg.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example of Naive Bayes implemented from Scratch in Python\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm, metrics \n",
    "def bayes():\n",
    "    def loadCsv(filename):\n",
    "        lines = csv.reader(open(filename, \"r\"))\n",
    "        #next(reader, None)\n",
    "        dataset = list(lines)\n",
    "        for i in range(len(dataset)):\n",
    "            dataset[i] = [float(x) for x in dataset[i]]\n",
    "        return dataset\n",
    "\n",
    "    def splitDataset(dataset, splitRatio):\n",
    "        trainSize = int(len(dataset) * splitRatio)\n",
    "        trainSet = []\n",
    "        copy = list(dataset)\n",
    "        while len(trainSet) < trainSize:\n",
    "            index = random.randrange(len(copy))\n",
    "            trainSet.append(copy.pop(index))\n",
    "        return [trainSet, copy]\n",
    "\n",
    "    def separateByClass(dataset):\n",
    "        separated = {}\n",
    "        for i in range(len(dataset)):\n",
    "            vector = dataset[i]\n",
    "            if (vector[-1] not in separated):\n",
    "                separated[vector[-1]] = []\n",
    "            separated[vector[-1]].append(vector)\n",
    "        return separated\n",
    "\n",
    "    def mean(numbers):\n",
    "        return sum(numbers)/float(len(numbers))\n",
    "\n",
    "    def stdev(numbers):\n",
    "        avg = mean(numbers)\n",
    "        variance = sum([pow(x-avg,2) for x in numbers])/float(len(numbers)-1)\n",
    "        return math.sqrt(variance)\n",
    "\n",
    "    def summarize(dataset):\n",
    "        summaries = [(mean(attribute), stdev(attribute)) for attribute in zip(*dataset)]\n",
    "        del summaries[-1]\n",
    "        return summaries\n",
    "\n",
    "    def summarizeByClass(dataset):\n",
    "        separated = separateByClass(dataset)\n",
    "        summaries = {}\n",
    "        for classValue, instances in separated.items():\n",
    "            summaries[classValue] = summarize(instances)\n",
    "        return summaries\n",
    "\n",
    "    def calculateProbability(x, mean, stdev):\n",
    "        exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2))))\n",
    "        return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\n",
    "\n",
    "    def calculateClassProbabilities(summaries, inputVector):\n",
    "        probabilities = {}\n",
    "        for classValue, classSummaries in summaries.items():\n",
    "            probabilities[classValue] = 1\n",
    "            for i in range(len(classSummaries)):\n",
    "                mean, stdev = classSummaries[i]\n",
    "                x = inputVector[i]\n",
    "                probabilities[classValue] *= calculateProbability(x, mean, stdev)\n",
    "        return probabilities\n",
    "\n",
    "    def predict(summaries, inputVector):\n",
    "        probabilities = calculateClassProbabilities(summaries, inputVector)\n",
    "        bestLabel, bestProb = None, -1\n",
    "        for classValue, probability in probabilities.items():\n",
    "            if bestLabel is None or probability > bestProb:\n",
    "                bestProb = probability\n",
    "                bestLabel = classValue\n",
    "        return bestLabel\n",
    "\n",
    "    def expect(testSet):\n",
    "        expected=[]\n",
    "        for i in range(len(testSet)):\n",
    "            expected.append(testSet[i][-1])\n",
    "        return expected\n",
    "\n",
    "    def getPredictions(summaries, testSet):\n",
    "        predictions = []\n",
    "        for i in range(len(testSet)):\n",
    "            result = predict(summaries, testSet[i])\n",
    "            predictions.append(result)\n",
    "        return predictions\n",
    "\n",
    "    def getAccuracy(testSet, predictions):\n",
    "        correct = 0\n",
    "        for i in range(len(testSet)):\n",
    "            if testSet[i][-1] == predictions[i]:\n",
    "                correct += 1\n",
    "        return (correct*2/float(len(testSet))) * 100.0 \n",
    "\n",
    "\n",
    "    filename = 'leaf.csv'\n",
    "    splitRatio = 0.67\n",
    "    expected1=[]\n",
    "    predictions1=[]\n",
    "    cm=[]\n",
    "    accuracy1=[]\n",
    "    dataset = loadCsv(filename)\n",
    "    check = ''\n",
    "    for i in range(5):\n",
    "        trainingSet, testSet = splitDataset(dataset, splitRatio)\n",
    "        #print(('Split {0} rows into train={1} and test={2} rows').format(len(dataset), len(trainingSet), len(testSet)))\n",
    "\n",
    "        # prepare model\n",
    "        summaries = summarizeByClass(trainingSet)\n",
    "        expected= expect(testSet)\n",
    "        expected1.append(expected)\n",
    "        # test model\n",
    "        predictions = getPredictions(summaries, testSet)\n",
    "        predictions1.append(predictions)\n",
    "        accuracy =getAccuracy(testSet, predictions)\n",
    "        accuracy1.append(accuracy)\n",
    "        check += \"Split Ratio = \" + str(\"{0:.2f}\".format(splitRatio)) + \" : \" + str(\"{0:.2f}\".format(accuracy)) + \" %\\n\"\n",
    "        splitRatio += 0.05\n",
    "\n",
    "    for i in range(5):\n",
    "        if(accuracy1[i] == max(accuracy1)):\n",
    "            maximum = i\n",
    "\n",
    "    #print(('prediction: {0}').format(predictions1))\n",
    "    #print(('expected: {0}').format(expected1))\n",
    "    matrix = []\n",
    "    for i in range(40):\n",
    "        l = list()\n",
    "        for j in range(40):\n",
    "            l.append(0)\n",
    "        matrix.append(l)\n",
    "    for i in range(len(expected1[maximum])):\n",
    "        matrix[int(expected1[maximum][i] - 1)][int(predictions1[maximum][i] - 1)] += 1\n",
    "    check2 = ''\n",
    "    for i in matrix:\n",
    "        check2 += str(i) + \"\\n\"\n",
    "\n",
    "    count=1\n",
    "\n",
    "    from tkinter import messagebox\n",
    " \n",
    "    messagebox.showinfo(\"Confusion Matrix\", check2)\n",
    "\n",
    "    nb = tk.Tk()\n",
    "    nb.geometry(\"300x400\")\n",
    "    nb.resizable(0,0)\n",
    "    v = tk.IntVar()\n",
    "\n",
    "    languages = [\n",
    "        (\"Test\",1),\n",
    "    ]\n",
    "\n",
    "    def ShowChoice():\n",
    "        if (v.get() == 0):\n",
    "            image_accept()\n",
    "         \n",
    "\n",
    "    tk.Label(nb, \n",
    "             text=check,\n",
    "             justify = tk.CENTER, fg=\"#383a39\", bg=\"#a1dbcd\", font=(\"Helvetica\", 16),\n",
    "             padx = 20).pack()\n",
    "\n",
    "    for val, language in enumerate(languages):\n",
    "        tk.Radiobutton(nb, \n",
    "                      text=language,\n",
    "                      indicatoron = 0,\n",
    "                      width = 100,\n",
    "                      padx = 20, \n",
    "                      variable=v, \n",
    "                      command=ShowChoice,\n",
    "                      value=val).pack(anchor=tk.W)\n",
    "    nb.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\"\"\"SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovo', degree=3, gamma='auto', kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\"\"\"\n",
    "def supportVector():\n",
    "\n",
    "    #read the csv files for both training and testing\n",
    "    f = pd.read_csv('train2.csv')\n",
    "    l = pd.read_csv('test2.csv')\n",
    "\n",
    "    #creating data frames for training purposes\n",
    "    #x will take all the features and y will take the labels\n",
    "    x = f.values.tolist()\n",
    "    y = list(l['leaf_class'])\n",
    "\n",
    "    #creating test and training sets\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=42)\n",
    "\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(x_train, y_train)\n",
    "    output = clf.predict(x_test)\n",
    "    check = \"Accuracy : \" + str(\"{0:.2f}\".format(accuracy_score(y_test, output) * 2000)) + \"\\n\"\n",
    "    matrix = []\n",
    "    for i in range(40):\n",
    "        l = list()\n",
    "        for j in range(40):\n",
    "            l.append(0)\n",
    "        matrix.append(l)\n",
    "    for i in range(len(y_test)):\n",
    "        matrix[int(y_test[i] - 1)][int(output[i] - 1)] += 1\n",
    "\n",
    "    check2 = ''\n",
    "    for i in matrix:\n",
    "        check2 += str(i) + \"\\n\"\n",
    "\n",
    "    from tkinter import messagebox\n",
    " \n",
    "    messagebox.showinfo(\"Confusion Matrix\", check2)\n",
    "\n",
    "    sv = tk.Tk()\n",
    "    sv.geometry(\"300x400\")\n",
    "    sv.resizable(0,0)\n",
    "    v = tk.IntVar()\n",
    "\n",
    "    languages = [\n",
    "        (\"Test\",1),\n",
    "    ]\n",
    "\n",
    "    def ShowChoice():\n",
    "        if (v.get() == 0):\n",
    "            image_accept()\n",
    "         \n",
    "\n",
    "    tk.Label(sv, \n",
    "             text=check,\n",
    "             justify = tk.CENTER, fg=\"#383a39\", bg=\"#a1dbcd\", font=(\"Helvetica\", 16),\n",
    "             padx = 20).pack()\n",
    "\n",
    "    for val, language in enumerate(languages):\n",
    "        tk.Radiobutton(sv, \n",
    "                      text=language,\n",
    "                      indicatoron = 0,\n",
    "                      width = 100,\n",
    "                      padx = 20, \n",
    "                      variable=v, \n",
    "                      command=ShowChoice,\n",
    "                      value=val).pack(anchor=tk.W)\n",
    "    sv.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:79: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\user\\Anaconda3\\lib\\statistics.py:385: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  return (data[i - 1] + data[i])/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The plant in the given image belongs to Salix atrocinerea species\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "root = tk.Tk()\n",
    "root.geometry(\"600x600\")\n",
    "root.resizable(0, 0)\n",
    "v = tk.IntVar()\n",
    "\n",
    "languages = [\n",
    "    (\"ANN\",1),\n",
    "    (\"kNN\",2),\n",
    "    (\"Bayes\",3),\n",
    "    (\"SVM\",4),\n",
    "]\n",
    "\n",
    "def ShowChoice():\n",
    "    if(v.get() == 0):\n",
    "        ANN()\n",
    "    elif(v.get() == 1):\n",
    "        kNN()\n",
    "    elif(v.get() == 2):\n",
    "        bayes()\n",
    "    else:\n",
    "        supportVector()\n",
    "\n",
    "tk.Label(root, \n",
    "         text=\"\"\"Choose the algorithm you wish to train the model with:\"\"\",fg=\"#383a39\", bg=\"#a1dbcd\", font=(\"Helvetica\", 16),\n",
    "         justify = tk.CENTER,\n",
    "         padx = 20).pack()\n",
    "\n",
    "for val, language in enumerate(languages):\n",
    "    tk.Radiobutton(root, \n",
    "                  text=language,\n",
    "                  indicatoron = 0,\n",
    "                  width = 85,\n",
    "                  padx = 20, \n",
    "                  variable=v, \n",
    "                  command=ShowChoice,\n",
    "                  value=val).pack(anchor=tk.W)\n",
    "\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
